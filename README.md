# ğŸ›ï¸ Intelligent Shopping Assistant

En AI-baseret, dialogstyret shopping-assistent, der hjÃ¦lper brugeren med at finde og sammenligne produkter ud fra egne behov, prÃ¦ferencer og spÃ¸rgsmÃ¥l. Agenten kan selv forbedre sine svar baseret pÃ¥ automatisk kritik og feedback.

---

## ğŸš€ Features

- FÃ¸rer intelligent dialog pÃ¥ engelsk (brugere kan dog ogsÃ¥ foretage samtale pÃ¥ dansk).
- Kan stille opklarende spÃ¸rgsmÃ¥l og forklare vigtige parametre.
- Henter aktuelle produkter via Google Shopping (SerpAPI).
- Sammenligner produkter i overskueligt punktformat med emojis.
- Giver personlig anbefaling med begrundelse.
- Output evalueres automatisk af en â€œcritic agentâ€ â€“ agenten kan forbedre sit output hvis evalueringen ikke er tilfredsstillende.

---

## ğŸ—‚ï¸ Dependencies

Projektet er baseret pÃ¥ **Python 3.11+** og bruger fÃ¸lgende eksterne pakker:

- `autogen` (fra Microsoft)
- `python-dotenv`
- `requests`
- `mistralai`

Installer alt med:

```bash
pip install -r requirements.txt
```

**requirements.txt eksempel:**

```
autogen
python-dotenv
requests
mistralai
```

---

## âš™ï¸ Setup

1. **Klon projektet**
   ```bash
   git clone https://github.com/sabr5840/Machine_learning_eksamen.git
   cd <projekt-mappe>
   ```
2. **Opret `.env` fil med nÃ¸dvendige nÃ¸gler (se synopse for korrekte nÃ¸gler):**
   ```
   SERPAPI_API_KEY=din_serpapi_nÃ¸gle
   MISTRAL_API_KEY=din_mistral_nÃ¸gle
   ```
3. **Installer dependencies**
   ```bash
   pip install -r requirements.txt
   ```

---

## ğŸ SÃ¥dan kÃ¸rer du koden

1. **Opret og aktiver et virtuelt miljÃ¸ (anbefales):**

   ```bash
   python -m venv venv
   source venv/bin/activate  # PÃ¥ Mac/Linux
   .\venv\Scripts\activate   # PÃ¥ Windows
   ```

2. **KÃ¸r hele shopping-agenten (interaktivt):**
   ```bash
   python agent/research_agent.py
   ```
   Agenten vil stille dig spÃ¸rgsmÃ¥l om dit Ã¸nskede produkt og foreslÃ¥ relevante produkter.

---

## ğŸ“ Projektstruktur

```
agent/
    research_agent.py         # Hovedagenten (dialog og workflow)
    agent_evaluation.py       # Evaluering/"critic agent"
tools/
    product_search.py         # Produkt-sÃ¸gning via SerpAPI
test_eval.py                 # Simpel evalueringstest (mock)
test_eval_loop.py            # Evaluering + feedback-loop (mock)
.env                         # Dine API-nÃ¸gler (IKKE til Git)
requirements.txt             # Dependencies
README.md                    # (denne fil)
use_cases.md                 # Brugsscenarier (eksempler)
```

---

## ğŸ“šUse-cases

Hvis du vil tilgÃ¥ alle use-cases, kan du trykke pÃ¥ dette link: [use-cases.md](use-cases.md)

---

## ğŸ§ª Testfiler â€“ Oversigt og FormÃ¥l

Projektet indeholder en rÃ¦kke testfiler, som gÃ¸r det nemt at verificere, at de vigtigste funktioner og integrationer virker som forventet. Herunder kan du lÃ¦se, hvad de enkelte testfiler bruges til:

### `test_rate_limiter.py`

Tester at vores rate limiter fungerer korrekt og overholder grÃ¦nser for hvor mange kald, der mÃ¥ ske til eksterne APIâ€™er indenfor et bestemt tidsinterval.  
**Eksempel:** Ved 3 kald per 5 sekunder vil filen vise, at de fÃ¸rste tre kald sker med det samme, mens det fjerde kald venter, indtil vinduet er gÃ¥et.

### `test_openai.py`

Sikrer, at forbindelsen til OpenAI APIâ€™et virker, og at vores API-nÃ¸gle er indlÃ¦st korrekt.  
Sender en simpel testbesked til GPT-3.5 og viser svaret i terminalen. Giver en fejlbesked, hvis der er problemer med nÃ¸glen eller netvÃ¦rket.

### `test_mock_output.py`

Tester formateringen af produktdata.  
Vi bruger en liste af fiktive (â€œmockâ€) produkter, som bliver sendt igennem funktionen `format_products`, sÃ¥ vi kan se, hvordan produkterne ville blive prÃ¦senteret for brugeren â€“ helt uden at hente rigtige data udefra.

### `test_eval.py`

Tester evalueringen af et eksempel pÃ¥ et agentsvar.  
Funktionen `evaluate_response` vurderer, hvor godt et svar matcher brugerens prompt, og resultatet vises i en letlÃ¦selig form. Bruges til at sikre, at vores evalueringslogik fungerer som forventet.

### `test_eval_loop.py`

Simulerer et feedback-loop, hvor agenten fÃ¥r flere forsÃ¸g til at forbedre sine svar.  
Indeholder tre forskellige agentsvar af varierende kvalitet og evaluerer dem Ã©t ad gangen. Hvis et svar ikke er godt nok, vises feedback, og der prÃ¸ves igen.  
Dette efterligner en iterativ proces, hvor agenten lÃ¦rer af feedback og forbedrer sine resultater.

#### Generelt

Disse testfiler gÃ¸r det hurtigt at afprÃ¸ve og validere enkelte dele af projektet, bÃ¥de ift. API-integration, databehandling og evaluering af agent-svar.  
Du kan kÃ¸re dem direkte fra terminalen, f.eks.:
